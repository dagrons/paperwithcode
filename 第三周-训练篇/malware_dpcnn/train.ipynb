{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6abd7e02",
   "metadata": {},
   "source": [
    "# 训练篇\n",
    "\n",
    "1. 选择nn.loss损失函数\n",
    "2. 选择torch.optim优化算法\n",
    "3. 设置超参数\n",
    "4. 设置tensorboard进行可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c055b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn # 包含loss和各种blocks, layers\n",
    "from torch.utils.data import * # 包括Dataset和DataLoader\n",
    "from tensorboardX import SummaryWriter \n",
    "\n",
    "from resnet import * \n",
    "from generate_dataset import * "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af4f3c4",
   "metadata": {},
   "source": [
    "配置如下：\n",
    "1. settings: 训练集地址和验证集地址\n",
    "2. writer for tensorboard\n",
    "3. prepare dataloader\n",
    "4. load model\n",
    "5. loss func \n",
    "6. optim \n",
    "7. let's go \n",
    "\n",
    "然后过程如下:\n",
    "```python\n",
    "for ep in range(EPOCHS):\n",
    "    training ...\n",
    "    validation ...\n",
    "testing ...\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "519d7a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5147da5e-4af0-4dc2-bb10-d18d0c249760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f0d896dbcc0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2db9cf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_dir):\n",
    "    # path for training and testing data\n",
    "    train_data_path = \"/share/mal/malware/data/train\"\n",
    "    test_data_path = \"/share/mal/malware/data/test\"\n",
    "    \n",
    "    # writer for debug\n",
    "    writer = SummaryWriter(comment=\"malware_classification%resnet34\")\n",
    "    \n",
    "    # prepare dataloader\n",
    "    train_set = generate_dataset(train_data_path)\n",
    "    test_set = generate_dataset(test_data_path)\n",
    "    train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=64, shuffle=True)\n",
    "    \n",
    "    # load model\n",
    "    model = ResNet(num_block=[3, 4, 6, 3], num_classes=8)\n",
    "    model.cuda()\n",
    "    model.train()\n",
    "    \n",
    "    # loss func\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # optim\n",
    "    optim = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "    \n",
    "    # let's go \n",
    "    EPOCH = 20\n",
    "    step = 0\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for ep in range(EPOCH):\n",
    "        # training\n",
    "        for idx, data in enumerate(train_loader):\n",
    "            x, y = data\n",
    "            y = torch.from_numpy(np.asarray(y, dtype=np.long))\n",
    "            y-=1 # 训练集标签从1-9，映射到0-8\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            \n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "            \n",
    "            if step % 10 == 0:\n",
    "                print (\"epoch {} step {}: loss={}\".format(ep, step, loss))\n",
    "            writer.add_scalar(\"Loss\", loss, step)\n",
    "            step += 1\n",
    "        \n",
    "        # validation\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        model.eval()\n",
    "        for idx, data in enumerate(test_loader):\n",
    "            x, y = data\n",
    "            y = torch.from_numpy(np.asarray(y, dtype=np.long))\n",
    "            y-=1\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "            y_pred = model(x)\n",
    "            prediction = torch.argmax(y_pred, 1)\n",
    "            correct += (prediction == y).sum()\n",
    "            total += len(y)\n",
    "        \n",
    "        acc = correct/total\n",
    "        print (\"epoch {}: acc={}\".format(ep, acc))\n",
    "        writer.add_scalar(\"acc\", acc, ep)\n",
    "        \n",
    "        # save the epoch model and replace the best model\n",
    "        model_path = os.path.join(model_dir, 'malware_classification%resnet34%{}.pth'.format(ep))\n",
    "        torch.save(model, model_path)\n",
    "        if acc > best_acc:\n",
    "            best_model_path = os.path.join(model_dir, 'malware_classification%resnet34%best.pth')\n",
    "            torch.save(model, best_model_path)\n",
    "            best_acc = acc\n",
    "            \n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cebb1b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 step 0: loss=2.076631784439087\n",
      "epoch 0 step 10: loss=2.07023286819458\n",
      "epoch 0 step 20: loss=2.0594799518585205\n",
      "epoch 0 step 30: loss=2.0616228580474854\n",
      "epoch 0 step 40: loss=2.0597167015075684\n",
      "epoch 0 step 50: loss=2.045849084854126\n",
      "epoch 0 step 60: loss=2.0501255989074707\n",
      "epoch 0 step 70: loss=2.0405056476593018\n",
      "epoch 0 step 80: loss=2.0442278385162354\n",
      "epoch 0 step 90: loss=2.0241730213165283\n",
      "epoch 0 step 100: loss=2.027639150619507\n",
      "epoch 0 step 110: loss=2.0041229724884033\n",
      "epoch 0 step 120: loss=2.0299246311187744\n",
      "epoch 0 step 130: loss=2.015204668045044\n",
      "epoch 0: acc=0.2918017506599426\n",
      "epoch 1 step 140: loss=1.9951720237731934\n",
      "epoch 1 step 150: loss=1.8323334455490112\n",
      "epoch 1 step 160: loss=1.716463327407837\n",
      "epoch 1 step 170: loss=1.7289382219314575\n",
      "epoch 1 step 180: loss=1.7048345804214478\n",
      "epoch 1 step 190: loss=1.7646193504333496\n",
      "epoch 1 step 200: loss=1.7421860694885254\n",
      "epoch 1 step 210: loss=1.778476357460022\n",
      "epoch 1 step 220: loss=1.8079018592834473\n",
      "epoch 1 step 230: loss=1.8045449256896973\n",
      "epoch 1 step 240: loss=1.3708726167678833\n",
      "epoch 1 step 250: loss=1.6347630023956299\n",
      "epoch 1 step 260: loss=1.9279124736785889\n",
      "epoch 1 step 270: loss=1.181958794593811\n",
      "epoch 1: acc=0.40574339032173157\n",
      "epoch 2 step 280: loss=1.2424196004867554\n",
      "epoch 2 step 290: loss=1.4669424295425415\n",
      "epoch 2 step 300: loss=1.6079872846603394\n",
      "epoch 2 step 310: loss=1.6077624559402466\n",
      "epoch 2 step 320: loss=1.1431130170822144\n",
      "epoch 2 step 330: loss=2.453887462615967\n",
      "epoch 2 step 340: loss=1.1463141441345215\n",
      "epoch 2 step 350: loss=1.1234641075134277\n",
      "epoch 2 step 360: loss=1.0441975593566895\n",
      "epoch 2 step 370: loss=1.8124637603759766\n",
      "epoch 2 step 380: loss=1.4624900817871094\n",
      "epoch 2 step 390: loss=1.224872350692749\n",
      "epoch 2 step 400: loss=1.2224915027618408\n",
      "epoch 2: acc=0.5808244347572327\n",
      "epoch 3 step 410: loss=0.9090261459350586\n",
      "epoch 3 step 420: loss=0.9419107437133789\n",
      "epoch 3 step 430: loss=1.2844321727752686\n",
      "epoch 3 step 440: loss=1.12497079372406\n",
      "epoch 3 step 450: loss=1.1798179149627686\n",
      "epoch 3 step 460: loss=1.2544548511505127\n",
      "epoch 3 step 470: loss=0.9130186438560486\n",
      "epoch 3 step 480: loss=1.0077643394470215\n",
      "epoch 3 step 490: loss=0.8351108431816101\n",
      "epoch 3 step 500: loss=1.0477542877197266\n",
      "epoch 3 step 510: loss=0.9238135814666748\n",
      "epoch 3 step 520: loss=1.3460173606872559\n",
      "epoch 3 step 530: loss=0.9908270239830017\n",
      "epoch 3 step 540: loss=1.7284877300262451\n",
      "epoch 3: acc=0.6007410883903503\n",
      "epoch 4 step 550: loss=1.3083497285842896\n",
      "epoch 4 step 560: loss=0.7043822407722473\n",
      "epoch 4 step 570: loss=1.1170789003372192\n",
      "epoch 4 step 580: loss=0.6936987042427063\n",
      "epoch 4 step 590: loss=0.747941255569458\n",
      "epoch 4 step 600: loss=0.5143482685089111\n",
      "epoch 4 step 610: loss=1.4654425382614136\n",
      "epoch 4 step 620: loss=0.9318171143531799\n",
      "epoch 4 step 630: loss=0.5307470560073853\n",
      "epoch 4 step 640: loss=0.7012572288513184\n",
      "epoch 4 step 650: loss=0.7906166911125183\n",
      "epoch 4 step 660: loss=1.083228349685669\n",
      "epoch 4 step 670: loss=0.40302175283432007\n",
      "epoch 4: acc=0.76887446641922\n",
      "epoch 5 step 680: loss=0.6439031958580017\n",
      "epoch 5 step 690: loss=0.6250712871551514\n",
      "epoch 5 step 700: loss=0.5804789662361145\n",
      "epoch 5 step 710: loss=0.6195903420448303\n",
      "epoch 5 step 720: loss=0.8325262665748596\n",
      "epoch 5 step 730: loss=0.6818496584892273\n",
      "epoch 5 step 740: loss=0.5826591849327087\n",
      "epoch 5 step 750: loss=0.5921631455421448\n",
      "epoch 5 step 760: loss=0.6947497129440308\n",
      "epoch 5 step 770: loss=0.5905311703681946\n",
      "epoch 5 step 780: loss=1.5043559074401855\n",
      "epoch 5 step 790: loss=0.5834976434707642\n",
      "epoch 5 step 800: loss=1.3876935243606567\n",
      "epoch 5 step 810: loss=0.5832043886184692\n",
      "epoch 5: acc=0.8077813982963562\n",
      "epoch 6 step 820: loss=0.7044337391853333\n",
      "epoch 6 step 830: loss=0.5756097435951233\n",
      "epoch 6 step 840: loss=0.4861207902431488\n",
      "epoch 6 step 850: loss=1.3041911125183105\n",
      "epoch 6 step 860: loss=0.7132050395011902\n",
      "epoch 6 step 870: loss=1.5079718828201294\n",
      "epoch 6 step 880: loss=0.8018811345100403\n",
      "epoch 6 step 890: loss=0.5227895975112915\n",
      "epoch 6 step 900: loss=1.009903073310852\n",
      "epoch 6 step 910: loss=0.7584176063537598\n",
      "epoch 6 step 920: loss=0.8306369185447693\n",
      "epoch 6 step 930: loss=0.8121117949485779\n",
      "epoch 6 step 940: loss=0.7133627533912659\n",
      "epoch 6 step 950: loss=0.6586207151412964\n",
      "epoch 6: acc=0.7586845755577087\n",
      "epoch 7 step 960: loss=0.6750427484512329\n",
      "epoch 7 step 970: loss=0.5972661375999451\n",
      "epoch 7 step 980: loss=0.678266704082489\n",
      "epoch 7 step 990: loss=0.4401393234729767\n",
      "epoch 7 step 1000: loss=0.5621533393859863\n",
      "epoch 7 step 1010: loss=0.4001680612564087\n",
      "epoch 7 step 1020: loss=0.4192483425140381\n",
      "epoch 7 step 1030: loss=0.5079178214073181\n",
      "epoch 7 step 1040: loss=0.6222171187400818\n",
      "epoch 7 step 1050: loss=0.3242550492286682\n",
      "epoch 7 step 1060: loss=0.4241602122783661\n",
      "epoch 7 step 1070: loss=0.444928377866745\n",
      "epoch 7 step 1080: loss=0.4575594663619995\n",
      "epoch 7: acc=0.8383510708808899\n",
      "epoch 8 step 1090: loss=0.39833858609199524\n",
      "epoch 8 step 1100: loss=0.35604965686798096\n",
      "epoch 8 step 1110: loss=0.2488897293806076\n",
      "epoch 8 step 1120: loss=0.499186247587204\n",
      "epoch 8 step 1130: loss=0.7857236266136169\n",
      "epoch 8 step 1140: loss=0.4914216101169586\n",
      "epoch 8 step 1150: loss=0.8890889883041382\n",
      "epoch 8 step 1160: loss=0.4898841381072998\n",
      "epoch 8 step 1170: loss=0.4272858798503876\n",
      "epoch 8 step 1180: loss=0.4284875690937042\n",
      "epoch 8 step 1190: loss=0.5190308690071106\n",
      "epoch 8 step 1200: loss=0.4229532480239868\n",
      "epoch 8 step 1210: loss=0.3881009519100189\n",
      "epoch 8 step 1220: loss=0.32510045170783997\n",
      "epoch 8: acc=0.82075035572052\n",
      "epoch 9 step 1230: loss=0.32940423488616943\n",
      "epoch 9 step 1240: loss=0.2464672476053238\n",
      "epoch 9 step 1250: loss=0.16422778367996216\n",
      "epoch 9 step 1260: loss=0.3674226999282837\n",
      "epoch 9 step 1270: loss=0.31488698720932007\n",
      "epoch 9 step 1280: loss=0.3033601939678192\n",
      "epoch 9 step 1290: loss=0.2430051565170288\n",
      "epoch 9 step 1300: loss=0.4849002957344055\n",
      "epoch 9 step 1310: loss=0.36619827151298523\n",
      "epoch 9 step 1320: loss=0.4272673726081848\n",
      "epoch 9 step 1330: loss=0.2893299162387848\n",
      "epoch 9 step 1340: loss=0.3785163164138794\n",
      "epoch 9 step 1350: loss=0.44905737042427063\n",
      "epoch 9: acc=0.8332561254501343\n",
      "epoch 10 step 1360: loss=0.4701334238052368\n",
      "epoch 10 step 1370: loss=0.3744738698005676\n",
      "epoch 10 step 1380: loss=0.2668832540512085\n",
      "epoch 10 step 1390: loss=0.34321871399879456\n",
      "epoch 10 step 1400: loss=0.342212975025177\n",
      "epoch 10 step 1410: loss=0.32081758975982666\n",
      "epoch 10 step 1420: loss=0.30741655826568604\n",
      "epoch 10 step 1430: loss=0.266754150390625\n",
      "epoch 10 step 1440: loss=0.39389169216156006\n",
      "epoch 10 step 1450: loss=0.5200905799865723\n",
      "epoch 10 step 1460: loss=0.3389021158218384\n",
      "epoch 10 step 1470: loss=0.3728170096874237\n",
      "epoch 10 step 1480: loss=0.41333791613578796\n",
      "epoch 10 step 1490: loss=0.9868399500846863\n",
      "epoch 10: acc=0.8314034342765808\n",
      "epoch 11 step 1500: loss=0.5365843176841736\n",
      "epoch 11 step 1510: loss=0.33289846777915955\n",
      "epoch 11 step 1520: loss=0.395408034324646\n",
      "epoch 11 step 1530: loss=0.41773921251296997\n",
      "epoch 11 step 1540: loss=0.2014142870903015\n",
      "epoch 11 step 1550: loss=0.37836748361587524\n",
      "epoch 11 step 1560: loss=0.38152527809143066\n",
      "epoch 11 step 1570: loss=0.12726645171642303\n",
      "epoch 11 step 1580: loss=0.20279361307621002\n",
      "epoch 11 step 1590: loss=0.28308191895484924\n",
      "epoch 11 step 1600: loss=0.4611963629722595\n",
      "epoch 11 step 1610: loss=0.5315371155738831\n",
      "epoch 11 step 1620: loss=0.3296012580394745\n",
      "epoch 11 step 1630: loss=0.22294507920742035\n",
      "epoch 11: acc=0.9008800387382507\n",
      "epoch 12 step 1640: loss=0.34877872467041016\n",
      "epoch 12 step 1650: loss=0.1799808144569397\n",
      "epoch 12 step 1660: loss=0.25998276472091675\n",
      "epoch 12 step 1670: loss=0.24020785093307495\n",
      "epoch 12 step 1680: loss=0.46199649572372437\n",
      "epoch 12 step 1690: loss=0.15580245852470398\n",
      "epoch 12 step 1700: loss=0.16623999178409576\n",
      "epoch 12 step 1710: loss=0.26030397415161133\n",
      "epoch 12 step 1720: loss=0.6514355540275574\n",
      "epoch 12 step 1730: loss=0.4198056161403656\n",
      "epoch 12 step 1740: loss=0.214521586894989\n",
      "epoch 12 step 1750: loss=0.20505769550800323\n",
      "epoch 12 step 1760: loss=0.3368825316429138\n",
      "epoch 12: acc=0.8730893731117249\n",
      "epoch 13 step 1770: loss=0.16155663132667542\n",
      "epoch 13 step 1780: loss=0.19156275689601898\n",
      "epoch 13 step 1790: loss=0.2525021731853485\n",
      "epoch 13 step 1800: loss=0.16067667305469513\n",
      "epoch 13 step 1810: loss=0.28189873695373535\n",
      "epoch 13 step 1820: loss=0.1350453794002533\n",
      "epoch 13 step 1830: loss=0.3102668523788452\n",
      "epoch 13 step 1840: loss=0.4159330725669861\n",
      "epoch 13 step 1850: loss=0.22143365442752838\n",
      "epoch 13 step 1860: loss=0.3576657176017761\n",
      "epoch 13 step 1870: loss=0.1913038045167923\n",
      "epoch 13 step 1880: loss=0.07724453508853912\n",
      "epoch 13 step 1890: loss=0.19810271263122559\n",
      "epoch 13 step 1900: loss=0.18426553905010223\n",
      "epoch 13: acc=0.9018063545227051\n",
      "epoch 14 step 1910: loss=2.370699405670166\n",
      "epoch 14 step 1920: loss=1.2774771451950073\n",
      "epoch 14 step 1930: loss=1.0969040393829346\n",
      "epoch 14 step 1940: loss=0.16034133732318878\n",
      "epoch 14 step 1950: loss=0.6328113675117493\n",
      "epoch 14 step 1960: loss=0.7629474997520447\n",
      "epoch 14 step 1970: loss=0.4040202498435974\n",
      "epoch 14 step 1980: loss=0.21704557538032532\n",
      "epoch 14 step 1990: loss=0.4293808341026306\n",
      "epoch 14 step 2000: loss=0.36132314801216125\n",
      "epoch 14 step 2010: loss=0.43266740441322327\n",
      "epoch 14 step 2020: loss=0.2413519322872162\n",
      "epoch 14 step 2030: loss=0.31127944588661194\n",
      "epoch 14: acc=0.9036591053009033\n",
      "epoch 15 step 2040: loss=0.24421587586402893\n",
      "epoch 15 step 2050: loss=0.12796372175216675\n",
      "epoch 15 step 2060: loss=0.38011786341667175\n",
      "epoch 15 step 2070: loss=0.6025438904762268\n",
      "epoch 15 step 2080: loss=0.36685582995414734\n",
      "epoch 15 step 2090: loss=0.33121517300605774\n",
      "epoch 15 step 2100: loss=0.2453359067440033\n",
      "epoch 15 step 2110: loss=0.5269076824188232\n",
      "epoch 15 step 2120: loss=0.2789730727672577\n",
      "epoch 15 step 2130: loss=0.2845543920993805\n",
      "epoch 15 step 2140: loss=0.25196757912635803\n",
      "epoch 15 step 2150: loss=0.615380048751831\n",
      "epoch 15 step 2160: loss=0.3369870185852051\n",
      "epoch 15 step 2170: loss=0.1967247873544693\n",
      "epoch 15: acc=0.9212598204612732\n",
      "epoch 16 step 2180: loss=0.3305802345275879\n",
      "epoch 16 step 2190: loss=0.14203721284866333\n",
      "epoch 16 step 2200: loss=0.22971168160438538\n",
      "epoch 16 step 2210: loss=0.15613988041877747\n",
      "epoch 16 step 2220: loss=0.2962726354598999\n",
      "epoch 16 step 2230: loss=0.26878392696380615\n",
      "epoch 16 step 2240: loss=0.07842562347650528\n",
      "epoch 16 step 2250: loss=0.14825841784477234\n",
      "epoch 16 step 2260: loss=0.20803570747375488\n",
      "epoch 16 step 2270: loss=0.2457943707704544\n",
      "epoch 16 step 2280: loss=0.4385091960430145\n",
      "epoch 16 step 2290: loss=0.3123376965522766\n",
      "epoch 16 step 2300: loss=0.13828915357589722\n",
      "epoch 16 step 2310: loss=0.3251201808452606\n",
      "epoch 16: acc=0.8462250828742981\n",
      "epoch 17 step 2320: loss=0.18525411188602448\n",
      "epoch 17 step 2330: loss=0.10864570736885071\n",
      "epoch 17 step 2340: loss=0.17030605673789978\n",
      "epoch 17 step 2350: loss=0.234417125582695\n",
      "epoch 17 step 2360: loss=0.13323090970516205\n",
      "epoch 17 step 2370: loss=0.12888172268867493\n",
      "epoch 17 step 2380: loss=0.28063881397247314\n",
      "epoch 17 step 2390: loss=0.08183716982603073\n",
      "epoch 17 step 2400: loss=0.2531202733516693\n",
      "epoch 17 step 2410: loss=0.2532471716403961\n",
      "epoch 17 step 2420: loss=0.41228604316711426\n",
      "epoch 17 step 2430: loss=0.17859013378620148\n",
      "epoch 17 step 2440: loss=0.27035194635391235\n",
      "epoch 17: acc=0.9217230081558228\n",
      "epoch 18 step 2450: loss=0.17515556514263153\n",
      "epoch 18 step 2460: loss=0.21493898332118988\n",
      "epoch 18 step 2470: loss=0.11163262277841568\n",
      "epoch 18 step 2480: loss=0.16044539213180542\n",
      "epoch 18 step 2490: loss=0.31401440501213074\n",
      "epoch 18 step 2500: loss=0.16617213189601898\n",
      "epoch 18 step 2510: loss=0.3166016936302185\n",
      "epoch 18 step 2520: loss=0.10049756616353989\n",
      "epoch 18 step 2530: loss=0.19076547026634216\n",
      "epoch 18 step 2540: loss=0.2509373724460602\n",
      "epoch 18 step 2550: loss=0.04410114884376526\n",
      "epoch 18 step 2560: loss=0.3278365135192871\n",
      "epoch 18 step 2570: loss=0.25572097301483154\n",
      "epoch 18 step 2580: loss=0.21310876309871674\n",
      "epoch 18: acc=0.8897637724876404\n",
      "epoch 19 step 2590: loss=0.16586367785930634\n",
      "epoch 19 step 2600: loss=0.0412360318005085\n",
      "epoch 19 step 2610: loss=0.13732151687145233\n",
      "epoch 19 step 2620: loss=0.3303487300872803\n",
      "epoch 19 step 2630: loss=0.22477900981903076\n",
      "epoch 19 step 2640: loss=0.1674012690782547\n",
      "epoch 19 step 2650: loss=0.15235164761543274\n",
      "epoch 19 step 2660: loss=0.20921137928962708\n",
      "epoch 19 step 2670: loss=0.10068821907043457\n",
      "epoch 19 step 2680: loss=0.9423038959503174\n",
      "epoch 19 step 2690: loss=0.64553302526474\n",
      "epoch 19 step 2700: loss=0.5614351034164429\n",
      "epoch 19 step 2710: loss=0.3846662938594818\n",
      "epoch 19: acc=0.8564149737358093\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/root/paperwithcode/第三周-训练篇/malware_dpcnn/trained_models/\" \n",
    "train(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f0b0a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存最优模型字典\n",
    "best_model_path = os.path.join(model_path, 'malware_classification%resnet34%best.pth')\n",
    "state_dict_path = os.path.join(model_path, 'malware_classification%resnet34%best.pt')\n",
    "model = ResNet(num_block=[3, 4, 6, 3])\n",
    "best_model = torch.load(best_model_path)\n",
    "torch.save(best_model.state_dict(), state_dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d133395-1d91-4037-b118-ca99563f144e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
