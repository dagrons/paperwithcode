{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6abd7e02",
   "metadata": {},
   "source": [
    "# 训练篇\n",
    "\n",
    "1. 选择nn.loss损失函数\n",
    "2. 选择torch.optim优化算法\n",
    "3. 设置超参数\n",
    "4. 设置tensorboard进行可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c055b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn # 包含loss和各种blocks, layers\n",
    "from torch.utils.data import * # 包括Dataset和DataLoader\n",
    "from tensorboardX import SummaryWriter \n",
    "\n",
    "from resnet import * \n",
    "from generate_dataset import * "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af4f3c4",
   "metadata": {},
   "source": [
    "配置如下：\n",
    "1. settings: 训练集地址和验证集地址\n",
    "2. writer for tensorboard\n",
    "3. prepare dataloader\n",
    "4. load model\n",
    "5. loss func \n",
    "6. optim \n",
    "7. let's go \n",
    "\n",
    "然后过程如下:\n",
    "```python\n",
    "for ep in range(EPOCHS):\n",
    "    training ...\n",
    "    validation ...\n",
    "testing ...\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "519d7a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2db9cf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_dir):\n",
    "    # path for training and testing data\n",
    "    train_data_path = \"/share/mal/malware/data/train\"\n",
    "    test_data_path = \"/share/mal/malware/data/test\"\n",
    "    \n",
    "    # writer for debug\n",
    "    writer = SummaryWriter(comment=\"malware_classification%resnet34\")\n",
    "    \n",
    "    # prepare dataloader\n",
    "    train_set = generate_dataset(train_data_path)\n",
    "    test_set = generate_dataset(test_data_path)\n",
    "    train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=64, shuffle=True)\n",
    "    \n",
    "    # load model\n",
    "    model = ResNet(num_block=[3, 4, 6, 3])\n",
    "    model.cuda()\n",
    "    model.train()\n",
    "    \n",
    "    # loss func\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # optim\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    # let's go \n",
    "    EPOCH = 20\n",
    "    step = 0\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for ep in range(EPOCH):\n",
    "        # training\n",
    "        for idx, data in enumerate(train_loader):\n",
    "            x, y = data\n",
    "            y = torch.from_numpy(np.asarray(y, dtype=np.long))\n",
    "            y-=1 # 训练集标签从1-9，映射到0-8\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            \n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "            \n",
    "            if step % 10 == 0:\n",
    "                print (\"epoch {} step {}: loss={}\".format(ep, step, loss))\n",
    "            writer.add_scalar(\"Loss\", loss, step)\n",
    "            step += 1\n",
    "        \n",
    "        # validation\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        model.eval()\n",
    "        for idx, data in enumerate(test_loader):\n",
    "            x, y = data\n",
    "            y = torch.from_numpy(np.asarray(y, dtype=np.long))\n",
    "            y-=1\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            \n",
    "            y_pred = model(x)\n",
    "            prediction = torch.argmax(y_pred, 1)\n",
    "            correct += (prediction == y).sum()\n",
    "            total += len(y)\n",
    "        \n",
    "        acc = correct/total\n",
    "        print (\"epoch {}: acc={}\".format(ep, acc))\n",
    "        writer.add_scalar(\"acc\", acc, ep)\n",
    "        \n",
    "        # save the epoch model and replace the best model\n",
    "        model_path = os.path.join(model_dir, 'malware_classification%resnet34%{}.pth'.format(ep))\n",
    "        torch.save(model, model_path)\n",
    "        if acc > best_acc:\n",
    "            best_model_path = os.path.join(model_dir, 'malware_classification%resnet34%best.pth')\n",
    "            torch.save(model, best_model_path)\n",
    "            best_acc = acc\n",
    "            \n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cebb1b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 step 0: loss=2.196451425552368\n",
      "epoch 0 step 10: loss=1.6483924388885498\n",
      "epoch 0 step 20: loss=1.0914372205734253\n",
      "epoch 0 step 30: loss=1.2241926193237305\n",
      "epoch 0 step 40: loss=0.7833883166313171\n",
      "epoch 0 step 50: loss=0.7656913995742798\n",
      "epoch 0 step 60: loss=0.7335379123687744\n",
      "epoch 0 step 70: loss=0.7754487991333008\n",
      "epoch 0 step 80: loss=0.7694524526596069\n",
      "epoch 0 step 90: loss=0.9672061800956726\n",
      "epoch 0 step 100: loss=0.6955627202987671\n",
      "epoch 0 step 110: loss=0.5186516642570496\n",
      "epoch 0 step 120: loss=0.6631216406822205\n",
      "epoch 0 step 130: loss=0.42911431193351746\n",
      "epoch 0: acc=0.6617443561553955\n",
      "epoch 1 step 140: loss=8.570575714111328\n",
      "epoch 1 step 150: loss=2.164341449737549\n",
      "epoch 1 step 160: loss=2.023650646209717\n",
      "epoch 1 step 170: loss=1.996954083442688\n",
      "epoch 1 step 180: loss=1.8642414808273315\n",
      "epoch 1 step 190: loss=1.8081952333450317\n",
      "epoch 1 step 200: loss=1.8754520416259766\n",
      "epoch 1 step 210: loss=2.1661369800567627\n",
      "epoch 1 step 220: loss=1.638825535774231\n",
      "epoch 1 step 230: loss=1.6896113157272339\n",
      "epoch 1 step 240: loss=1.6598047018051147\n",
      "epoch 1 step 250: loss=1.68898344039917\n",
      "epoch 1 step 260: loss=1.6826064586639404\n",
      "epoch 1 step 270: loss=1.464815378189087\n",
      "epoch 1: acc=0.5209967494010925\n",
      "epoch 2 step 280: loss=1.3512628078460693\n",
      "epoch 2 step 290: loss=1.746564507484436\n",
      "epoch 2 step 300: loss=1.5051146745681763\n",
      "epoch 2 step 310: loss=1.2189942598342896\n",
      "epoch 2 step 320: loss=1.1715731620788574\n",
      "epoch 2 step 330: loss=1.748660683631897\n",
      "epoch 2 step 340: loss=1.2925888299942017\n",
      "epoch 2 step 350: loss=1.0272055864334106\n",
      "epoch 2 step 360: loss=1.3209245204925537\n",
      "epoch 2 step 370: loss=1.111861228942871\n",
      "epoch 2 step 380: loss=0.9659872055053711\n",
      "epoch 2 step 390: loss=1.019576072692871\n",
      "epoch 2 step 400: loss=0.882222056388855\n",
      "epoch 2: acc=0.3285648226737976\n",
      "epoch 3 step 410: loss=1.5365270376205444\n",
      "epoch 3 step 420: loss=1.3623243570327759\n",
      "epoch 3 step 430: loss=1.3467501401901245\n",
      "epoch 3 step 440: loss=1.134940266609192\n",
      "epoch 3 step 450: loss=0.9062013626098633\n",
      "epoch 3 step 460: loss=0.6539148688316345\n",
      "epoch 3 step 470: loss=0.9717046022415161\n",
      "epoch 3 step 480: loss=0.7048266530036926\n",
      "epoch 3 step 490: loss=0.5082195997238159\n",
      "epoch 3 step 500: loss=0.6487488746643066\n",
      "epoch 3 step 510: loss=1.1869239807128906\n",
      "epoch 3 step 520: loss=0.9108790159225464\n",
      "epoch 3 step 530: loss=0.6621693968772888\n",
      "epoch 3 step 540: loss=0.5451813340187073\n",
      "epoch 3: acc=0.7734194397926331\n",
      "epoch 4 step 550: loss=0.4626483917236328\n",
      "epoch 4 step 560: loss=0.48096662759780884\n",
      "epoch 4 step 570: loss=0.5553711652755737\n",
      "epoch 4 step 580: loss=0.7719663977622986\n",
      "epoch 4 step 590: loss=0.9672232866287231\n",
      "epoch 4 step 600: loss=0.8301921486854553\n",
      "epoch 4 step 610: loss=0.7519705295562744\n",
      "epoch 4 step 620: loss=0.6405417323112488\n",
      "epoch 4 step 630: loss=0.7091091275215149\n",
      "epoch 4 step 640: loss=0.4453533887863159\n",
      "epoch 4 step 650: loss=0.6597989797592163\n",
      "epoch 4 step 660: loss=0.6569571495056152\n",
      "epoch 4 step 670: loss=0.5425992608070374\n",
      "epoch 4: acc=0.8431010246276855\n",
      "epoch 5 step 680: loss=0.5103377103805542\n",
      "epoch 5 step 690: loss=0.6479326486587524\n",
      "epoch 5 step 700: loss=0.4201061725616455\n",
      "epoch 5 step 710: loss=0.5454610586166382\n",
      "epoch 5 step 720: loss=0.381694495677948\n",
      "epoch 5 step 730: loss=0.38209524750709534\n",
      "epoch 5 step 740: loss=0.6519487500190735\n",
      "epoch 5 step 750: loss=0.3698757588863373\n",
      "epoch 5 step 760: loss=0.4156438708305359\n",
      "epoch 5 step 770: loss=0.32114076614379883\n",
      "epoch 5 step 780: loss=0.5070721507072449\n",
      "epoch 5 step 790: loss=0.5743260383605957\n",
      "epoch 5 step 800: loss=0.4654797613620758\n",
      "epoch 5 step 810: loss=0.4374973773956299\n",
      "epoch 5: acc=0.8601753115653992\n",
      "epoch 6 step 820: loss=0.36868995428085327\n",
      "epoch 6 step 830: loss=0.17008349299430847\n",
      "epoch 6 step 840: loss=0.29598528146743774\n",
      "epoch 6 step 850: loss=0.4024210572242737\n",
      "epoch 6 step 860: loss=0.4032038450241089\n",
      "epoch 6 step 870: loss=0.6028853058815002\n",
      "epoch 6 step 880: loss=0.6923795342445374\n",
      "epoch 6 step 890: loss=0.31447091698646545\n",
      "epoch 6 step 900: loss=0.5885071158409119\n",
      "epoch 6 step 910: loss=0.3868922293186188\n",
      "epoch 6 step 920: loss=0.5429835319519043\n",
      "epoch 6 step 930: loss=0.7422224283218384\n",
      "epoch 6 step 940: loss=0.3117339611053467\n",
      "epoch 6 step 950: loss=0.5148985981941223\n",
      "epoch 6: acc=0.8458698391914368\n",
      "epoch 7 step 960: loss=0.4570528268814087\n",
      "epoch 7 step 970: loss=0.31331920623779297\n",
      "epoch 7 step 980: loss=0.4419093430042267\n",
      "epoch 7 step 990: loss=0.3483998477458954\n",
      "epoch 7 step 1000: loss=0.42257431149482727\n",
      "epoch 7 step 1010: loss=0.5916516184806824\n",
      "epoch 7 step 1020: loss=0.25702324509620667\n",
      "epoch 7 step 1030: loss=0.31887802481651306\n",
      "epoch 7 step 1040: loss=0.4313235580921173\n",
      "epoch 7 step 1050: loss=0.4639914035797119\n",
      "epoch 7 step 1060: loss=0.3489987552165985\n",
      "epoch 7 step 1070: loss=0.17715221643447876\n",
      "epoch 7 step 1080: loss=0.40162208676338196\n",
      "epoch 7: acc=0.9017074108123779\n",
      "epoch 8 step 1090: loss=0.24585972726345062\n",
      "epoch 8 step 1100: loss=0.27825021743774414\n",
      "epoch 8 step 1110: loss=0.30893397331237793\n",
      "epoch 8 step 1120: loss=0.41230762004852295\n",
      "epoch 8 step 1130: loss=0.29768165946006775\n",
      "epoch 8 step 1140: loss=2.0263121128082275\n",
      "epoch 8 step 1150: loss=0.9739900231361389\n",
      "epoch 8 step 1160: loss=0.9015546441078186\n",
      "epoch 8 step 1170: loss=0.9127711057662964\n",
      "epoch 8 step 1180: loss=0.663777768611908\n",
      "epoch 8 step 1190: loss=0.6242386102676392\n",
      "epoch 8 step 1200: loss=1.048454999923706\n",
      "epoch 8 step 1210: loss=0.593929648399353\n",
      "epoch 8 step 1220: loss=0.6512283086776733\n",
      "epoch 8: acc=0.8121827244758606\n",
      "epoch 9 step 1230: loss=0.5508624911308289\n",
      "epoch 9 step 1240: loss=0.7011280059814453\n",
      "epoch 9 step 1250: loss=0.5180527567863464\n",
      "epoch 9 step 1260: loss=0.7086009979248047\n",
      "epoch 9 step 1270: loss=0.49223870038986206\n",
      "epoch 9 step 1280: loss=0.3678204417228699\n",
      "epoch 9 step 1290: loss=0.4837419390678406\n",
      "epoch 9 step 1300: loss=0.534503161907196\n",
      "epoch 9 step 1310: loss=0.6584974527359009\n",
      "epoch 9 step 1320: loss=0.5526372790336609\n",
      "epoch 9 step 1330: loss=0.464959979057312\n",
      "epoch 9 step 1340: loss=0.6315661668777466\n",
      "epoch 9 step 1350: loss=0.6193857789039612\n",
      "epoch 9: acc=0.8638671040534973\n",
      "epoch 10 step 1360: loss=0.40783825516700745\n",
      "epoch 10 step 1370: loss=0.448001891374588\n",
      "epoch 10 step 1380: loss=0.37677374482154846\n",
      "epoch 10 step 1390: loss=0.3195953369140625\n",
      "epoch 10 step 1400: loss=0.27529966831207275\n",
      "epoch 10 step 1410: loss=0.5346660614013672\n",
      "epoch 10 step 1420: loss=0.22760388255119324\n",
      "epoch 10 step 1430: loss=0.21735788881778717\n",
      "epoch 10 step 1440: loss=0.23536287248134613\n",
      "epoch 10 step 1450: loss=0.46740028262138367\n",
      "epoch 10 step 1460: loss=0.43052345514297485\n",
      "epoch 10 step 1470: loss=0.4380217492580414\n",
      "epoch 10 step 1480: loss=0.38520291447639465\n",
      "epoch 10 step 1490: loss=0.39056864380836487\n",
      "epoch 10: acc=0.8975542187690735\n",
      "epoch 11 step 1500: loss=0.2935291528701782\n",
      "epoch 11 step 1510: loss=0.20614749193191528\n",
      "epoch 11 step 1520: loss=0.39277705550193787\n",
      "epoch 11 step 1530: loss=0.5522322654724121\n",
      "epoch 11 step 1540: loss=0.2762947380542755\n",
      "epoch 11 step 1550: loss=0.3891870081424713\n",
      "epoch 11 step 1560: loss=0.32049912214279175\n",
      "epoch 11 step 1570: loss=0.24799881875514984\n",
      "epoch 11 step 1580: loss=0.26525697112083435\n",
      "epoch 11 step 1590: loss=0.1341177523136139\n",
      "epoch 11 step 1600: loss=0.18416140973567963\n",
      "epoch 11 step 1610: loss=0.2771322727203369\n",
      "epoch 11 step 1620: loss=0.1916886866092682\n",
      "epoch 11 step 1630: loss=0.23892992734909058\n",
      "epoch 11: acc=0.9206275939941406\n",
      "epoch 12 step 1640: loss=0.16432103514671326\n",
      "epoch 12 step 1650: loss=0.3862368166446686\n",
      "epoch 12 step 1660: loss=0.15554040670394897\n",
      "epoch 12 step 1670: loss=0.3653477430343628\n",
      "epoch 12 step 1680: loss=0.45322826504707336\n",
      "epoch 12 step 1690: loss=0.21131934225559235\n",
      "epoch 12 step 1700: loss=0.35999220609664917\n",
      "epoch 12 step 1710: loss=0.2606099843978882\n",
      "epoch 12 step 1720: loss=0.4852023124694824\n",
      "epoch 12 step 1730: loss=0.2744898200035095\n",
      "epoch 12 step 1740: loss=0.3683381974697113\n",
      "epoch 12 step 1750: loss=0.35620033740997314\n",
      "epoch 12 step 1760: loss=0.43924257159233093\n",
      "epoch 12: acc=0.9183202385902405\n",
      "epoch 13 step 1770: loss=0.1934494972229004\n",
      "epoch 13 step 1780: loss=0.15702813863754272\n",
      "epoch 13 step 1790: loss=0.3714117407798767\n",
      "epoch 13 step 1800: loss=0.16423042118549347\n",
      "epoch 13 step 1810: loss=0.17744308710098267\n",
      "epoch 13 step 1820: loss=0.3155556619167328\n",
      "epoch 13 step 1830: loss=0.20477911829948425\n",
      "epoch 13 step 1840: loss=0.3599383533000946\n",
      "epoch 13 step 1850: loss=0.15042147040367126\n",
      "epoch 13 step 1860: loss=0.3137431740760803\n",
      "epoch 13 step 1870: loss=0.40140894055366516\n",
      "epoch 13 step 1880: loss=0.2649748921394348\n",
      "epoch 13 step 1890: loss=0.33874717354774475\n",
      "epoch 13 step 1900: loss=0.11789131164550781\n",
      "epoch 13: acc=0.9303184151649475\n",
      "epoch 14 step 1910: loss=0.21803084015846252\n",
      "epoch 14 step 1920: loss=0.19901815056800842\n",
      "epoch 14 step 1930: loss=0.10926265269517899\n",
      "epoch 14 step 1940: loss=0.21949514746665955\n",
      "epoch 14 step 1950: loss=0.1867830604314804\n",
      "epoch 14 step 1960: loss=0.22580668330192566\n",
      "epoch 14 step 1970: loss=0.3271104693412781\n",
      "epoch 14 step 1980: loss=0.2468915432691574\n",
      "epoch 14 step 1990: loss=0.1934068500995636\n",
      "epoch 14 step 2000: loss=0.29417088627815247\n",
      "epoch 14 step 2010: loss=0.14105921983718872\n",
      "epoch 14 step 2020: loss=0.17424795031547546\n",
      "epoch 14 step 2030: loss=0.1499769538640976\n",
      "epoch 14: acc=0.914167046546936\n",
      "epoch 15 step 2040: loss=0.34144267439842224\n",
      "epoch 15 step 2050: loss=0.39927437901496887\n",
      "epoch 15 step 2060: loss=0.2864533066749573\n",
      "epoch 15 step 2070: loss=0.25765955448150635\n",
      "epoch 15 step 2080: loss=0.11880955845117569\n",
      "epoch 15 step 2090: loss=0.22257046401500702\n",
      "epoch 15 step 2100: loss=0.22400853037834167\n",
      "epoch 15 step 2110: loss=0.19870121777057648\n",
      "epoch 15 step 2120: loss=0.2892625033855438\n",
      "epoch 15 step 2130: loss=0.22066257894039154\n",
      "epoch 15 step 2140: loss=0.12292779982089996\n",
      "epoch 15 step 2150: loss=0.1893913447856903\n",
      "epoch 15 step 2160: loss=0.1976662129163742\n",
      "epoch 15 step 2170: loss=0.2554195523262024\n",
      "epoch 15: acc=0.8726349472999573\n",
      "epoch 16 step 2180: loss=0.2110815793275833\n",
      "epoch 16 step 2190: loss=0.38545602560043335\n",
      "epoch 16 step 2200: loss=0.41993290185928345\n",
      "epoch 16 step 2210: loss=0.27493613958358765\n",
      "epoch 16 step 2220: loss=0.14791297912597656\n",
      "epoch 16 step 2230: loss=0.26097479462623596\n",
      "epoch 16 step 2240: loss=0.2604593336582184\n",
      "epoch 16 step 2250: loss=0.27145594358444214\n",
      "epoch 16 step 2260: loss=0.2713020443916321\n",
      "epoch 16 step 2270: loss=0.18648742139339447\n",
      "epoch 16 step 2280: loss=0.05479366332292557\n",
      "epoch 16 step 2290: loss=0.13651560246944427\n",
      "epoch 16 step 2300: loss=1.9879897832870483\n",
      "epoch 16 step 2310: loss=1.0025840997695923\n",
      "epoch 16: acc=0.7471157908439636\n",
      "epoch 17 step 2320: loss=0.6071994304656982\n",
      "epoch 17 step 2330: loss=1.0547527074813843\n",
      "epoch 17 step 2340: loss=0.6377270221710205\n",
      "epoch 17 step 2350: loss=0.5985434651374817\n",
      "epoch 17 step 2360: loss=0.555496335029602\n",
      "epoch 17 step 2370: loss=0.46527332067489624\n",
      "epoch 17 step 2380: loss=0.5622019171714783\n",
      "epoch 17 step 2390: loss=0.3567954897880554\n",
      "epoch 17 step 2400: loss=0.2641557455062866\n",
      "epoch 17 step 2410: loss=0.2906627058982849\n",
      "epoch 17 step 2420: loss=0.24942846596240997\n",
      "epoch 17 step 2430: loss=0.13610213994979858\n",
      "epoch 17 step 2440: loss=0.3943847417831421\n",
      "epoch 17: acc=0.9155514240264893\n",
      "epoch 18 step 2450: loss=0.4917947053909302\n",
      "epoch 18 step 2460: loss=0.5836876034736633\n",
      "epoch 18 step 2470: loss=0.7839869260787964\n",
      "epoch 18 step 2480: loss=0.5174242854118347\n",
      "epoch 18 step 2490: loss=0.2891734540462494\n",
      "epoch 18 step 2500: loss=0.20301590859889984\n",
      "epoch 18 step 2510: loss=0.3379044234752655\n",
      "epoch 18 step 2520: loss=0.3808373808860779\n",
      "epoch 18 step 2530: loss=0.24740764498710632\n",
      "epoch 18 step 2540: loss=0.2152438461780548\n",
      "epoch 18 step 2550: loss=0.26330721378326416\n",
      "epoch 18 step 2560: loss=0.19949305057525635\n",
      "epoch 18 step 2570: loss=0.3007640540599823\n",
      "epoch 18 step 2580: loss=0.16564680635929108\n",
      "epoch 18: acc=0.9289339780807495\n",
      "epoch 19 step 2590: loss=0.22311264276504517\n",
      "epoch 19 step 2600: loss=0.2196338176727295\n",
      "epoch 19 step 2610: loss=0.24024063348770142\n",
      "epoch 19 step 2620: loss=0.19188307225704193\n",
      "epoch 19 step 2630: loss=0.24502888321876526\n",
      "epoch 19 step 2640: loss=0.10420958697795868\n",
      "epoch 19 step 2650: loss=0.0906761884689331\n",
      "epoch 19 step 2660: loss=0.11366896331310272\n",
      "epoch 19 step 2670: loss=0.05474609509110451\n",
      "epoch 19 step 2680: loss=0.08813846111297607\n",
      "epoch 19 step 2690: loss=0.43660226464271545\n",
      "epoch 19 step 2700: loss=0.23539750277996063\n",
      "epoch 19 step 2710: loss=0.260545015335083\n",
      "epoch 19: acc=0.9455468058586121\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/root/paperwithcode/第三周-训练篇/malware_dpcnn/trained_models/\" \n",
    "train(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f0b0a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存最优模型字典\n",
    "best_model_path = os.path.join(model_path, 'malware_classification%resnet34%best.pth')\n",
    "state_dict_path = os.path.join(model_path, 'malware_classification%resnet34%best.pt')\n",
    "model = ResNet(num_block=[3, 4, 6, 3])\n",
    "best_model = torch.load(best_model_path)\n",
    "torch.save(best_model.state_dict(), state_dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae60b50c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
