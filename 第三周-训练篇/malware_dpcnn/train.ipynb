{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6abd7e02",
   "metadata": {},
   "source": [
    "# 训练篇\n",
    "\n",
    "1. 选择nn.loss损失函数\n",
    "2. 选择torch.optim优化算法\n",
    "3. 设置超参数\n",
    "4. 设置tensorboard进行可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c055b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn # 包含loss和各种blocks, layers\n",
    "from torch.utils.data import * # 包括Dataset和DataLoader\n",
    "from tensorboardX import SummaryWriter \n",
    "\n",
    "from resnet import * \n",
    "from generate_dataset import * "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af4f3c4",
   "metadata": {},
   "source": [
    "配置如下：\n",
    "1. settings: 训练集地址和验证集地址\n",
    "2. writer for tensorboard\n",
    "3. prepare dataloader\n",
    "4. load model\n",
    "5. loss func \n",
    "6. optim \n",
    "7. let's go \n",
    "\n",
    "然后过程如下:\n",
    "```python\n",
    "for ep in range(EPOCHS):\n",
    "    training ...\n",
    "    validation ...\n",
    "testing ...\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "519d7a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5147da5e-4af0-4dc2-bb10-d18d0c249760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f550d320cc0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2db9cf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_dir):\n",
    "    # path for training and testing data\n",
    "    train_data_path = \"/share/mal/tmp/mal/train\"\n",
    "    test_data_path = \"/share/mal/tmp/mal/test\"\n",
    "    \n",
    "    # writer for debug\n",
    "    writer = SummaryWriter(comment=\"malware_classification%resnet34\")\n",
    "    \n",
    "    # prepare dataloader\n",
    "    train_set = generate_dataset(train_data_path)\n",
    "    test_set = generate_dataset(test_data_path)\n",
    "    train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=64, shuffle=True)\n",
    "    \n",
    "    # load model\n",
    "    model = ResNet(num_block=[3, 4, 6, 3], num_classes=9)\n",
    "    model.cuda()\n",
    "    model.train()\n",
    "    \n",
    "    # loss func\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # optim\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    # let's go \n",
    "    EPOCH = 20\n",
    "    step = 0\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for ep in range(EPOCH):\n",
    "        # training\n",
    "        for idx, data in enumerate(train_loader):\n",
    "            x, y = data\n",
    "            y = torch.from_numpy(np.asarray(y, dtype=np.long))\n",
    "            y-=1 # 训练集标签从1-9，映射到0-8\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            \n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "            \n",
    "            if step % 10 == 0:\n",
    "                print (\"epoch {} step {}: loss={}\".format(ep, step, loss))\n",
    "            writer.add_scalar(\"Loss\", loss, step)\n",
    "            step += 1\n",
    "        \n",
    "        # validation\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        model.eval()\n",
    "        for idx, data in enumerate(test_loader):\n",
    "            x, y = data\n",
    "            y = torch.from_numpy(np.asarray(y, dtype=np.long))\n",
    "            y-=1\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "            y_pred = model(x)\n",
    "            prediction = torch.argmax(y_pred, 1)\n",
    "            correct += (prediction == y).sum()\n",
    "            total += len(y)\n",
    "        \n",
    "        acc = correct/total\n",
    "        print (\"epoch {}: acc={}\".format(ep, acc))\n",
    "        writer.add_scalar(\"acc\", acc, ep)\n",
    "        \n",
    "        # save the epoch model and replace the best model\n",
    "        model_path = os.path.join(model_dir, 'malware_classification%resnet34%{}.pth'.format(ep))\n",
    "        torch.save(model, model_path)\n",
    "        if acc > best_acc:\n",
    "            best_model_path = os.path.join(model_dir, 'malware_classification%resnet34%best.pth')\n",
    "            torch.save(model, best_model_path)\n",
    "            best_acc = acc\n",
    "            \n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cebb1b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 step 0: loss=2.2055020332336426\n",
      "epoch 0 step 10: loss=1.5764442682266235\n",
      "epoch 0 step 20: loss=1.2501105070114136\n",
      "epoch 0 step 30: loss=1.1748971939086914\n",
      "epoch 0 step 40: loss=0.9152734875679016\n",
      "epoch 0 step 50: loss=0.7790653109550476\n",
      "epoch 0 step 60: loss=0.790437638759613\n",
      "epoch 0 step 70: loss=0.8054605722427368\n",
      "epoch 0 step 80: loss=1.6085131168365479\n",
      "epoch 0 step 90: loss=0.6463132500648499\n",
      "epoch 0 step 100: loss=0.6345608234405518\n",
      "epoch 0 step 110: loss=0.6703757643699646\n",
      "epoch 0 step 120: loss=0.6758723855018616\n",
      "epoch 0 step 130: loss=0.6089318990707397\n",
      "epoch 0: acc=0.5085371136665344\n",
      "epoch 1 step 140: loss=2.3388733863830566\n",
      "epoch 1 step 150: loss=2.1149935722351074\n",
      "epoch 1 step 160: loss=1.6574522256851196\n",
      "epoch 1 step 170: loss=1.865393877029419\n",
      "epoch 1 step 180: loss=1.8195676803588867\n",
      "epoch 1 step 190: loss=1.8472682237625122\n",
      "epoch 1 step 200: loss=1.6907707452774048\n",
      "epoch 1 step 210: loss=1.6089190244674683\n",
      "epoch 1 step 220: loss=1.7783348560333252\n",
      "epoch 1 step 230: loss=1.7210381031036377\n",
      "epoch 1 step 240: loss=1.67011296749115\n",
      "epoch 1 step 250: loss=1.600430965423584\n",
      "epoch 1 step 260: loss=1.4814406633377075\n",
      "epoch 1 step 270: loss=1.5688085556030273\n",
      "epoch 1: acc=0.4347023367881775\n",
      "epoch 2 step 280: loss=1.917699933052063\n",
      "epoch 2 step 290: loss=2.616582155227661\n",
      "epoch 2 step 300: loss=1.9114899635314941\n",
      "epoch 2 step 310: loss=1.7306931018829346\n",
      "epoch 2 step 320: loss=1.7418802976608276\n",
      "epoch 2 step 330: loss=1.6248294115066528\n",
      "epoch 2 step 340: loss=1.3492387533187866\n",
      "epoch 2 step 350: loss=1.4220833778381348\n",
      "epoch 2 step 360: loss=1.3146660327911377\n",
      "epoch 2 step 370: loss=1.0721255540847778\n",
      "epoch 2 step 380: loss=1.1147512197494507\n",
      "epoch 2 step 390: loss=1.086261510848999\n",
      "epoch 2 step 400: loss=1.1553722620010376\n",
      "epoch 2: acc=0.6100599765777588\n",
      "epoch 3 step 410: loss=1.1373544931411743\n",
      "epoch 3 step 420: loss=1.057278037071228\n",
      "epoch 3 step 430: loss=0.8462035059928894\n",
      "epoch 3 step 440: loss=1.1336835622787476\n",
      "epoch 3 step 450: loss=1.2040126323699951\n",
      "epoch 3 step 460: loss=1.3424009084701538\n",
      "epoch 3 step 470: loss=0.9035488367080688\n",
      "epoch 3 step 480: loss=1.1193482875823975\n",
      "epoch 3 step 490: loss=0.9718034863471985\n",
      "epoch 3 step 500: loss=1.032074213027954\n",
      "epoch 3 step 510: loss=0.690973162651062\n",
      "epoch 3 step 520: loss=0.988771378993988\n",
      "epoch 3 step 530: loss=0.9595535397529602\n",
      "epoch 3 step 540: loss=1.7057284116744995\n",
      "epoch 3: acc=0.6225196123123169\n",
      "epoch 4 step 550: loss=1.1091697216033936\n",
      "epoch 4 step 560: loss=0.9648433923721313\n",
      "epoch 4 step 570: loss=0.8213637471199036\n",
      "epoch 4 step 580: loss=0.8226920962333679\n",
      "epoch 4 step 590: loss=0.8788089156150818\n",
      "epoch 4 step 600: loss=0.6532717943191528\n",
      "epoch 4 step 610: loss=1.1241629123687744\n",
      "epoch 4 step 620: loss=0.9699989557266235\n",
      "epoch 4 step 630: loss=1.0861742496490479\n",
      "epoch 4 step 640: loss=0.7703702449798584\n",
      "epoch 4 step 650: loss=0.7251626253128052\n",
      "epoch 4 step 660: loss=0.7631088495254517\n",
      "epoch 4 step 670: loss=0.7270900011062622\n",
      "epoch 4: acc=0.7554222345352173\n",
      "epoch 5 step 680: loss=0.8525856137275696\n",
      "epoch 5 step 690: loss=0.6075822710990906\n",
      "epoch 5 step 700: loss=1.7356576919555664\n",
      "epoch 5 step 710: loss=1.1580406427383423\n",
      "epoch 5 step 720: loss=1.1630785465240479\n",
      "epoch 5 step 730: loss=0.9857121706008911\n",
      "epoch 5 step 740: loss=0.8265185952186584\n",
      "epoch 5 step 750: loss=1.7407715320587158\n",
      "epoch 5 step 760: loss=1.333617925643921\n",
      "epoch 5 step 770: loss=0.8816380500793457\n",
      "epoch 5 step 780: loss=1.0234293937683105\n",
      "epoch 5 step 790: loss=0.8028207421302795\n",
      "epoch 5 step 800: loss=0.6906630992889404\n",
      "epoch 5 step 810: loss=0.7186923027038574\n",
      "epoch 5: acc=0.7318874001502991\n",
      "epoch 6 step 820: loss=0.6328521966934204\n",
      "epoch 6 step 830: loss=0.8841989040374756\n",
      "epoch 6 step 840: loss=0.8012299537658691\n",
      "epoch 6 step 850: loss=0.6273537874221802\n",
      "epoch 6 step 860: loss=0.47745171189308167\n",
      "epoch 6 step 870: loss=0.607056736946106\n",
      "epoch 6 step 880: loss=0.6503458619117737\n",
      "epoch 6 step 890: loss=0.764988899230957\n",
      "epoch 6 step 900: loss=1.147667646408081\n",
      "epoch 6 step 910: loss=0.7959800362586975\n",
      "epoch 6 step 920: loss=0.7817959785461426\n",
      "epoch 6 step 930: loss=0.9989448189735413\n",
      "epoch 6 step 940: loss=0.8673616647720337\n",
      "epoch 6 step 950: loss=0.8843013048171997\n",
      "epoch 6: acc=0.7448084950447083\n",
      "epoch 7 step 960: loss=0.6821351647377014\n",
      "epoch 7 step 970: loss=0.7435199022293091\n",
      "epoch 7 step 980: loss=0.6386207342147827\n",
      "epoch 7 step 990: loss=0.6309646964073181\n",
      "epoch 7 step 1000: loss=0.6655852794647217\n",
      "epoch 7 step 1010: loss=0.5339869260787964\n",
      "epoch 7 step 1020: loss=0.46944040060043335\n",
      "epoch 7 step 1030: loss=0.6376827359199524\n",
      "epoch 7 step 1040: loss=0.5439932942390442\n",
      "epoch 7 step 1050: loss=0.7779855132102966\n",
      "epoch 7 step 1060: loss=0.5746212601661682\n",
      "epoch 7 step 1070: loss=0.593981146812439\n",
      "epoch 7 step 1080: loss=0.6171584129333496\n",
      "epoch 7: acc=0.7821873426437378\n",
      "epoch 8 step 1090: loss=0.6616010069847107\n",
      "epoch 8 step 1100: loss=1.5727943181991577\n",
      "epoch 8 step 1110: loss=1.4417439699172974\n",
      "epoch 8 step 1120: loss=0.685394823551178\n",
      "epoch 8 step 1130: loss=0.7029956579208374\n",
      "epoch 8 step 1140: loss=0.759279727935791\n",
      "epoch 8 step 1150: loss=0.9190027713775635\n",
      "epoch 8 step 1160: loss=0.9787895679473877\n",
      "epoch 8 step 1170: loss=0.9226576089859009\n",
      "epoch 8 step 1180: loss=0.6519572734832764\n",
      "epoch 8 step 1190: loss=0.8331570029258728\n",
      "epoch 8 step 1200: loss=0.35910123586654663\n",
      "epoch 8 step 1210: loss=0.7144429683685303\n",
      "epoch 8 step 1220: loss=1.1103894710540771\n",
      "epoch 8: acc=0.6760498285293579\n",
      "epoch 9 step 1230: loss=0.8572039008140564\n",
      "epoch 9 step 1240: loss=0.9433345794677734\n",
      "epoch 9 step 1250: loss=0.8030027151107788\n",
      "epoch 9 step 1260: loss=0.9862452745437622\n",
      "epoch 9 step 1270: loss=0.5371494293212891\n",
      "epoch 9 step 1280: loss=0.6169235110282898\n",
      "epoch 9 step 1290: loss=0.7377802729606628\n",
      "epoch 9 step 1300: loss=0.7013149857521057\n",
      "epoch 9 step 1310: loss=0.6200451254844666\n",
      "epoch 9 step 1320: loss=0.49768176674842834\n",
      "epoch 9 step 1330: loss=0.7317571043968201\n",
      "epoch 9 step 1340: loss=0.6221705675125122\n",
      "epoch 9 step 1350: loss=0.38151267170906067\n",
      "epoch 9: acc=0.8094139099121094\n",
      "epoch 10 step 1360: loss=0.5955537557601929\n",
      "epoch 10 step 1370: loss=0.7239813804626465\n",
      "epoch 10 step 1380: loss=0.5323981046676636\n",
      "epoch 10 step 1390: loss=0.528866171836853\n",
      "epoch 10 step 1400: loss=0.4581129550933838\n",
      "epoch 10 step 1410: loss=0.5929015874862671\n",
      "epoch 10 step 1420: loss=0.19583910703659058\n",
      "epoch 10 step 1430: loss=0.43103986978530884\n",
      "epoch 10 step 1440: loss=0.34265825152397156\n",
      "epoch 10 step 1450: loss=0.5072868466377258\n",
      "epoch 10 step 1460: loss=0.24693085253238678\n",
      "epoch 10 step 1470: loss=0.511527419090271\n",
      "epoch 10 step 1480: loss=0.30501240491867065\n",
      "epoch 10 step 1490: loss=0.5956642627716064\n",
      "epoch 10: acc=0.815874457359314\n",
      "epoch 11 step 1500: loss=0.4150994122028351\n",
      "epoch 11 step 1510: loss=0.3091496229171753\n",
      "epoch 11 step 1520: loss=0.33110523223876953\n",
      "epoch 11 step 1530: loss=0.5715876221656799\n",
      "epoch 11 step 1540: loss=0.5215229988098145\n",
      "epoch 11 step 1550: loss=0.36501339077949524\n",
      "epoch 11 step 1560: loss=0.4856642484664917\n",
      "epoch 11 step 1570: loss=0.2047589123249054\n",
      "epoch 11 step 1580: loss=0.20610852539539337\n",
      "epoch 11 step 1590: loss=0.4053300619125366\n",
      "epoch 11 step 1600: loss=0.4094567596912384\n",
      "epoch 11 step 1610: loss=0.1957990825176239\n",
      "epoch 11 step 1620: loss=0.33523160219192505\n",
      "epoch 11 step 1630: loss=0.6109651327133179\n",
      "epoch 11: acc=0.8758652210235596\n",
      "epoch 12 step 1640: loss=0.3625921607017517\n",
      "epoch 12 step 1650: loss=0.3495469391345978\n",
      "epoch 12 step 1660: loss=0.20199516415596008\n",
      "epoch 12 step 1670: loss=0.5487620234489441\n",
      "epoch 12 step 1680: loss=0.21093446016311646\n",
      "epoch 12 step 1690: loss=0.35810601711273193\n",
      "epoch 12 step 1700: loss=0.3021845519542694\n",
      "epoch 12 step 1710: loss=0.4223618805408478\n",
      "epoch 12 step 1720: loss=0.4182516634464264\n",
      "epoch 12 step 1730: loss=0.356245219707489\n",
      "epoch 12 step 1740: loss=0.5488903522491455\n",
      "epoch 12 step 1750: loss=0.4955843687057495\n",
      "epoch 12 step 1760: loss=0.8097994923591614\n",
      "epoch 12: acc=0.8467927575111389\n",
      "epoch 13 step 1770: loss=0.6963434815406799\n",
      "epoch 13 step 1780: loss=0.4053943157196045\n",
      "epoch 13 step 1790: loss=0.6031287312507629\n",
      "epoch 13 step 1800: loss=0.46717560291290283\n",
      "epoch 13 step 1810: loss=0.5503802299499512\n",
      "epoch 13 step 1820: loss=0.5981181859970093\n",
      "epoch 13 step 1830: loss=0.4079520106315613\n",
      "epoch 13 step 1840: loss=0.37399032711982727\n",
      "epoch 13 step 1850: loss=0.400874525308609\n",
      "epoch 13 step 1860: loss=0.4628249704837799\n",
      "epoch 13 step 1870: loss=0.3114999532699585\n",
      "epoch 13 step 1880: loss=0.4625624418258667\n",
      "epoch 13 step 1890: loss=0.5097737312316895\n",
      "epoch 13 step 1900: loss=0.49372389912605286\n",
      "epoch 13: acc=0.8703275918960571\n",
      "epoch 14 step 1910: loss=0.35650479793548584\n",
      "epoch 14 step 1920: loss=0.5594371557235718\n",
      "epoch 14 step 1930: loss=0.5257022380828857\n",
      "epoch 14 step 1940: loss=0.22560009360313416\n",
      "epoch 14 step 1950: loss=0.4264291226863861\n",
      "epoch 14 step 1960: loss=0.21063685417175293\n",
      "epoch 14 step 1970: loss=0.32884567975997925\n",
      "epoch 14 step 1980: loss=1.0836471319198608\n",
      "epoch 14 step 1990: loss=0.4751918911933899\n",
      "epoch 14 step 2000: loss=0.49584314227104187\n",
      "epoch 14 step 2010: loss=0.5376749634742737\n",
      "epoch 14 step 2020: loss=0.3919830918312073\n",
      "epoch 14 step 2030: loss=0.2673390209674835\n",
      "epoch 14: acc=0.8684817552566528\n",
      "epoch 15 step 2040: loss=0.28383567929267883\n",
      "epoch 15 step 2050: loss=0.4313911497592926\n",
      "epoch 15 step 2060: loss=0.6413915157318115\n",
      "epoch 15 step 2070: loss=0.37988734245300293\n",
      "epoch 15 step 2080: loss=0.3480522334575653\n",
      "epoch 15 step 2090: loss=0.25336506962776184\n",
      "epoch 15 step 2100: loss=0.2275901436805725\n",
      "epoch 15 step 2110: loss=0.48413005471229553\n",
      "epoch 15 step 2120: loss=0.3542177379131317\n",
      "epoch 15 step 2130: loss=0.370342880487442\n",
      "epoch 15 step 2140: loss=0.23791587352752686\n",
      "epoch 15 step 2150: loss=0.4936203360557556\n",
      "epoch 15 step 2160: loss=0.23694780468940735\n",
      "epoch 15 step 2170: loss=0.20071901381015778\n",
      "epoch 15: acc=0.8984771370887756\n",
      "epoch 16 step 2180: loss=0.22204264998435974\n",
      "epoch 16 step 2190: loss=0.44812247157096863\n",
      "epoch 16 step 2200: loss=0.16151326894760132\n",
      "epoch 16 step 2210: loss=0.17402450740337372\n",
      "epoch 16 step 2220: loss=0.281738817691803\n",
      "epoch 16 step 2230: loss=0.38960614800453186\n",
      "epoch 16 step 2240: loss=0.35739630460739136\n",
      "epoch 16 step 2250: loss=0.31548768281936646\n",
      "epoch 16 step 2260: loss=0.3727690279483795\n",
      "epoch 16 step 2270: loss=0.32146376371383667\n",
      "epoch 16 step 2280: loss=0.271085649728775\n",
      "epoch 16 step 2290: loss=0.15260936319828033\n",
      "epoch 16 step 2300: loss=0.20597706735134125\n",
      "epoch 16 step 2310: loss=0.2357359528541565\n",
      "epoch 16: acc=0.9201660752296448\n",
      "epoch 17 step 2320: loss=0.2632722556591034\n",
      "epoch 17 step 2330: loss=0.32418522238731384\n",
      "epoch 17 step 2340: loss=0.3686025142669678\n",
      "epoch 17 step 2350: loss=0.20827586948871613\n",
      "epoch 17 step 2360: loss=0.1839587241411209\n",
      "epoch 17 step 2370: loss=0.20194612443447113\n",
      "epoch 17 step 2380: loss=0.4029540419578552\n",
      "epoch 17 step 2390: loss=0.15423034131526947\n",
      "epoch 17 step 2400: loss=0.34300822019577026\n",
      "epoch 17 step 2410: loss=0.3717810809612274\n",
      "epoch 17 step 2420: loss=0.3074372410774231\n",
      "epoch 17 step 2430: loss=0.36298868060112\n",
      "epoch 17 step 2440: loss=0.1449929177761078\n",
      "epoch 17: acc=0.9155514240264893\n",
      "epoch 18 step 2450: loss=0.4073880612850189\n",
      "epoch 18 step 2460: loss=0.2778218388557434\n",
      "epoch 18 step 2470: loss=0.3314131498336792\n",
      "epoch 18 step 2480: loss=0.4041372239589691\n",
      "epoch 18 step 2490: loss=0.5227723717689514\n",
      "epoch 18 step 2500: loss=0.6331304907798767\n",
      "epoch 18 step 2510: loss=0.5187130570411682\n",
      "epoch 18 step 2520: loss=0.6584919691085815\n",
      "epoch 18 step 2530: loss=0.5639880895614624\n",
      "epoch 18 step 2540: loss=0.44158369302749634\n",
      "epoch 18 step 2550: loss=0.5783739686012268\n",
      "epoch 18 step 2560: loss=0.2923412024974823\n",
      "epoch 18 step 2570: loss=0.4754141867160797\n",
      "epoch 18 step 2580: loss=0.4287368059158325\n",
      "epoch 18: acc=0.8841716647148132\n",
      "epoch 19 step 2590: loss=0.28605034947395325\n",
      "epoch 19 step 2600: loss=0.45356425642967224\n",
      "epoch 19 step 2610: loss=0.44887861609458923\n",
      "epoch 19 step 2620: loss=0.3374387323856354\n",
      "epoch 19 step 2630: loss=0.330862820148468\n",
      "epoch 19 step 2640: loss=0.36586427688598633\n",
      "epoch 19 step 2650: loss=0.36099132895469666\n",
      "epoch 19 step 2660: loss=0.3302119970321655\n",
      "epoch 19 step 2670: loss=0.47016987204551697\n",
      "epoch 19 step 2680: loss=0.3740752339363098\n",
      "epoch 19 step 2690: loss=0.19903254508972168\n",
      "epoch 19 step 2700: loss=0.37310031056404114\n",
      "epoch 19 step 2710: loss=0.35820087790489197\n",
      "epoch 19: acc=0.8652514815330505\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/root/paperwithcode/第三周-训练篇/malware_dpcnn/trained_models/\" \n",
    "train(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0b0a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存最优模型字典\n",
    "best_model_path = os.path.join(model_path, 'malware_classification%resnet34%best.pth')\n",
    "state_dict_path = os.path.join(model_path, 'malware_classification%resnet34%best.pt')\n",
    "model = ResNet(num_block=[3, 4, 6, 3])\n",
    "best_model = torch.load(best_model_path)\n",
    "torch.save(best_model.state_dict(), state_dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d133395-1d91-4037-b118-ca99563f144e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
